# üß† Tutorial: Redes Neurais Artificiais do Zero
### Baseado na obra de David Kopec | Implementa√ß√£o em Python

Este guia serve como material de apoio para estudantes e desenvolvedores que desejam entender a implementa√ß√£o de uma **Rede Neural Artificial (ANN)** constru√≠da puramente em Python, focando nos fundamentos matem√°ticos e na arquitetura de c√≥digo, sem o uso de frameworks externos.

---

## 1. O Conceito Fundamental
Uma Rede Neural Artificial √© inspirada no funcionamento biol√≥gico do c√©rebro humano. O objetivo √© criar um sistema capaz de **aprender** a mapear entradas (inputs) para sa√≠das (outputs) atrav√©s de exemplos.

### A Estrutura B√°sica do Projeto
O c√≥digo est√° dividido em tr√™s classes principais que abstraem a complexidade:
1.  **Neuron (Neur√¥nio):** A unidade b√°sica de processamento.
2.  **Layer (Camada):** Um conjunto de neur√¥nios trabalhando em paralelo.
3.  **Network (Rede):** O gerenciador que conecta as camadas e executa o aprendizado.

---

## 2. O Neur√¥nio (`Neuron`)
Cada neur√¥nio recebe dados, processa-os e decide o quanto "disparar" de sinal para o pr√≥ximo.

![Diagrama do Neur√¥nio](../img/neurons.jpeg)

### A Matem√°tica Interna
O neur√¥nio realiza duas opera√ß√µes principais:

1.  **Combina√ß√£o Linear (Dot Product):** Multiplica as entradas pelos **pesos** ($w$) e soma com um vi√©s (**bias**).
    $$z = (x_1 \cdot w_1) + (x_2 \cdot w_2) + ... + bias$$

2.  **Fun√ß√£o de Ativa√ß√£o:** O resultado $z$ passa por uma fun√ß√£o que "esmaga" o valor para um intervalo conhecido (geralmente entre 0 e 1). Neste projeto, usamos a **Sigmoide**:
    $$S(x) = \frac{1}{1 + e^{-x}}$$

> **Nota:** A derivada da Sigmoide ($S'(x) = S(x) * (1 - S(x))$) √© crucial para o algoritmo de aprendizagem (backpropagation).

---

## 3. Arquitetura da Rede (`Layer` e `Network`)
As redes neurais modernas s√£o organizadas em camadas sequenciais.

* **Input Layer:** Recebe os dados brutos.
* **Hidden Layers:** Onde a "m√°gica" acontece. Extraem caracter√≠sticas complexas dos dados.
* **Output Layer:** Entrega a previs√£o final (ex: Classifica√ß√£o da esp√©cie da planta).

### Fluxo de Dados (Feedforward)
A informa√ß√£o viaja em sentido √∫nico:
`Input` $\rightarrow$ `Processamento na Camada Oculta` $\rightarrow$ `Ativa√ß√£o` $\rightarrow$ `Output`

No c√≥digo, o m√©todo `outputs()` da classe `Network` √© respons√°vel por propagar esse sinal camada por camada at√© o final.

---

## 4. O Aprendizado (Backpropagation)
Como a rede aprende? Ajustando os **Pesos** e o **Bias** para minimizar o erro.

O algoritmo **Backpropagation** (Propaga√ß√£o Reversa) funciona em 4 passos c√≠clicos:
1.  **Feedforward:** A rede faz uma previs√£o com os pesos atuais.
2.  **C√°lculo do Erro:** Compara a previs√£o com a resposta real (esperada).
3.  **C√°lculo dos Deltas:** Calcula a responsabilidade de cada neur√¥nio no erro final.
4.  **Atualiza√ß√£o:** Ajusta os pesos levemente na dire√ß√£o oposta ao erro, multiplicado por uma **Taxa de Aprendizado** (Learning Rate).

---

## 5. Estrutura do C√≥digo
O projeto √© modular para facilitar o estudo. Abaixo, um resumo das responsabilidades:

| Classe/Fun√ß√£o | Responsabilidade |
| :--- | :--- |
| `util.py` | Fun√ß√µes auxiliares (produto escalar, sigmoide, derivada). |
| `Neuron` | Armazena `weights`, `learning_rate`, `output_cache` e `delta`. |
| `Layer` | Gerencia uma lista de neur√¥nios. |
| `Network` | Orquestra o treino (`train`) e a valida√ß√£o (`validate`). |

### Exemplo de Uso

```python
from ann import Network

# 1. Definir a estrutura (ex: 2 entradas, 4 ocultos, 3 sa√≠das)
structure = [2, 4, 3]
rede = Network(structure, learning_rate=0.3)

# 2. Treinar com dados (Inputs e Esperados)
# Exemplo cl√°ssico: Dataset Iris
rede.train(inputs, expecteds)

# 3. Validar
resultado = rede.validate(test_inputs, test_expecteds)
print(f"Acur√°cia da rede: {resultado}%")